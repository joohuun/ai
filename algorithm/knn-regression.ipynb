{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-최근점 이웃 회귀 (KNN-Regression) \n",
    "- 샘플에 가장 가까운 샘플 k개 선택. 회귀이기에 이웃한 샘플의 타깃은 어떤 클래스가 아니라 임의의 수치임. 이 수치들의 평균을 구하여 새로운 샘플의 타깃값 예측.\n",
    "- 분류에서는 이웃의 레이블 개수를 확인해서 다수결로 정했지만, 회귀에서는 이웃들의 평균을 계산한다는 점에서 차이가 있음.    \n",
    "- https://rebro.kr/184"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "regress = KNeighborsRegressor(n_neighbors=5, weights='uniform', algorithm='auto', \n",
    "                              leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsRegressor Classe의 기본 구성\n",
    "- n_neighbors: int, 이웃의 수인 K를 결정한다. default=5\n",
    "- weights: {'uniform', 'distance} or callable. default=uniform   \n",
    "    uniform: 각각의 이웃이 모두 동일한 가중치를 갖는다.   \n",
    "    distance: 거리가 가까울수록 더 높은 가중치를 가져 더 큰 영향을 미치게 된다.   \n",
    "    callable: 사용자가 직접 정의한 함수를 사용할 수도 있다. 거리가 저장된 배열을 입력으로 받고 가중치가 저장된 배열을 반환하는 함수가 되어야 한다.\n",
    "- algorithm: auto, ball_tree, kd_tree, brute. default=auto   \n",
    "    auto: 입력된 훈련데이터에 기반하여 가장 적절한 알고리즘을 사용   \n",
    "- leaf_size: int, default:30   \n",
    "    ball-tree나 KD-Tree의 leaf size를 결정한다.   \n",
    "    이는 트리를 저장하기 위한 메모리뿐만 아니라, 트리의 구성과 쿼리의 처리속도에 영향을 미친다.\n",
    "- p: int   \n",
    "    p=1이면, 맨핸튼 거리   \n",
    "    p=2이면, 유클리드 거리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "6.48074069840786\n"
     ]
    }
   ],
   "source": [
    "# 맨해튼 거리\n",
    "def manhattan_distance(A, B):\n",
    "    distance = 0\n",
    "    for i in range(len(A)):\n",
    "        distance += abs(A[i] - B[i])\n",
    "    return distance\n",
    " \n",
    "print(manhattan_distance(A=[1, 5, 7, 9], B=[2, 3, 6, 15]))\n",
    "\n",
    "\n",
    "def euclidean_distance(A, B):\n",
    "  distance = 0\n",
    "  for i in range(len(A)):\n",
    "    distance += (A[i] - B[i]) ** 2\n",
    "  return distance ** 0.5\n",
    "  \n",
    "print(euclidean_distance(A=[1, 5, 7, 9], B=[2, 3, 6, 15]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "perch_length = np.array([8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0, 21.0,\n",
    "       21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5, 22.5, 22.7,\n",
    "       23.0, 23.5, 24.0, 24.0, 24.6, 25.0, 25.6, 26.5, 27.3, 27.5, 27.5,\n",
    "       27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0, 36.5, 36.0, 37.0, 37.0,\n",
    "       39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 42.0, 43.0, 43.0, 43.5,\n",
    "       44.0])\n",
    "perch_weight = np.array([5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0,\n",
    "       115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0,\n",
    "       150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0,\n",
    "       218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0,\n",
    "       556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0,\n",
    "       850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0,\n",
    "       1000.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(perch_length, perch_weight, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = train_input.reshape(-1, 1)\n",
    "test_input = test_input.reshape(-1, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결정계수 R^2\n",
    "- R^2 = 1 - {(타깃-예측)^2/(타깃-평균)^2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.992809406101064\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(train_input, train_target)\n",
    "\n",
    "# 테스트셋의 결정계수\n",
    "print(knr.score(test_input, test_target)) # 0.992809406101064"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9698823289099254\n"
     ]
    }
   ],
   "source": [
    "# 트레이닝셋의 결정 계수\n",
    "print(knr.score(train_input, train_target))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 과대적합 vs 과소적합          \n",
    "- 과소적합: 트레이닝셋보다 테스트셋의 점수가 높거나 두 점수가 모두 너무 낮은경우   \n",
    "- 과대적합: 트레이닝셋보다 테스트셋의 점수가 지나치게 낮은 경우         \n",
    "\n",
    "# 해결방법          \n",
    "- 과소적합의 경우 모델을 조금 더 복잡하게 만든다. 트레이닝셋에 더 잘 맞게 만들면 테스트셋의 점수가 조금 낮아 질 것이다.\n",
    "- k 값을 조정하여 모델의 복잡도를 바꿀 수 있다. 이웃의 수를 줄이면 트레이닝셋에 있는 국지적인 패턴에 민감해지고, 이웃의 수를 늘리면 데이터 전반에 있는 일반적인 패턴을 따르게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트셋: 0.9746459963987609\n",
      "트레이닝셋: 0.9804899950518966\n"
     ]
    }
   ],
   "source": [
    "knr.n_neighbors = 3\n",
    "knr.fit(train_input, train_target)\n",
    "print(\"테스트셋:\", knr.score(test_input, test_target)) \n",
    "print(\"트레이닝셋:\", knr.score(train_input, train_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1033.33333333]\n"
     ]
    }
   ],
   "source": [
    "# 훈련됭 모델을 이용하여 길이 100인 농어의 무게 예측\n",
    "print(knr.predict([[100]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f8b2d204ae218f62c782dc20b45e7c2b3614fb42963774991447c59af5951ea1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
